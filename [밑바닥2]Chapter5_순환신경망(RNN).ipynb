{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter5. 순환신경망 RNN\n",
    "- 피드포워드 feed forward : 흐름이 단방향인 신경망\n",
    "- 구성이 단순하고 구조를 이해하기 쉽고 많은 문제에 응용할 수 있다\n",
    "- 단순한 피드포워드 신경망에서는 시계열 데이터의 성질(패턴)을 충분히 학습할 수 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 확률과 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 word2vec을 확률 관점에서\n",
    "- CBOW는 사후 확률을 모델링. window size = 1 일때 CBOW 모델. $P(w_t|w_{t-1}, w_{t+1})$\n",
    "- 맥락을 왼쪽 윈도우만으로 한정. $P(w_t|w_{t-2}, w_{t-1})$ 손실함수 $L = -logP(w_t|w_{t-2}, w_{t-1})$\n",
    "- CBOW 모델을 학습시키는 목적은 맥락에서 타깃을 정확하게 추측하는 것\n",
    "- 이 목적을 위해 학습을 진행하면 단어의 의미가 인코딩된 단어의 분산표현을 얻을 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 언어 모델\n",
    "- 언어 모델은 단어 나열에 확률을 부여. 특정 단어의 시퀀스가 일어날 가능성이 어느 정도인지를 확률로 평가\n",
    "- 대표적인 예로 기계 번역과 음성 인식. 새로운 문장을 생성하는 용도(7장)\n",
    "- m개의 단어로 된 문장 $w_1, \\cdots, w_m$\n",
    "- 1~m 순서로 출현할 확률은 $P(w_1, \\cdots, w_m)$\n",
    "- 동시 확률을 사후 확률을 사용하여 분해하면\\\n",
    "$P(w_1, \\cdots, w_m) = P(w_m|w_1, \\cdots, w_{m-1})P(w_{m-1}|w_1, \\cdots, w_{m-2}) \\cdots P(w_3|w_1,w_2) P(w_2|w_1) P(w_1)$\\\n",
    "$\\Pi_{t=1}^{m}P(w_t|w_1, \\cdots, w_{t-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 CBOW 모델을 언어 모델로?\n",
    "\n",
    "- CBOW 모델을 언어 모델에 적용하면 맥락의 크기를 특정값으로 한정하여 근사적으로 나타낼 수 있다\n",
    "- $P\\left(w_1,\\ \\cdots ,\\ w_m\\right)\\ =\\ \\prod _{t=1}^mP\\left(w_t\\mid w_1,\\ \\cdots ,\\ w_{t-1}\\right)\\ \\approx \\ \\prod _{t=1}^mP\\left(w_t\\mid w_{t-2},\\ w_{t-1}\\right)$\n",
    "- 맥락을 왼쪽 2개의 단어로 한정하여 근사적으로 나타낼 수 있다\n",
    "- 확률이 그 직전 N개의 사건에만 의존할 대, 이를 N층 마르코프 연쇄라고 한다. 위의 모델은 2층 마르코프 연쇄\n",
    "- 맥락의 크기는 임의 길이로 설정할 수 있지면 결국 특정 길이로 고정\n",
    "- 맥락 크기는 얼마든지 키울 수 있지만 CBOW 모델에서는 맥락 안의 단어 순서가 무시된다는 한계가 있다\n",
    "- 맥락의 단어 순서도 고려한 모델이 바람직 → 맥락의 단어 벡터를 은닉층에 연결하는 방식(신경 확률론적 언어 모델 Neural Probabilistic Language Model) → 맥락의 크기에 비례해 가중치 매개변수도 늘어나게 된다\n",
    "- RNN은 맥락이 아무리 길더라도 그 맥락의 정보를 기억. RNN을 사용하면 아무리 긴 시계열 데이터에라도 대응할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RNN Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 순환하는 신경망\n",
    "- 순환하기 위해서는 닫힌 경로가 필요\n",
    "- 닫힌 경로 혹은 순환하는 경로가 존재해야 데이터가 같은 장소를 반복해 왕래할 수 있고 데이터가 순환하면서 정보가 끊임없이 갱신된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 순환구조 펼치기\n",
    "\n",
    "- RNN계층의 순환 구조를 펼침으로써 오른쪽으로 성장하는 긴 신경망이 된다\n",
    "- 이는 피드포워드 신경망과 같은 구조이지만, 다수의 RNN계층 모두가 실제로는 같은 계층인 것이 지금까지의 신경망과는 다르다\n",
    "- 각 시각의 RNN계층은 그 계층의 입력과 1개 전의 RNN계층으로부터의 출력을 받는다\n",
    "- $h_t\\ =\\ \\tanh \\left(h_{t-1}W_h+x_tW_x+b\\right)$\n",
    "- h는 상태를 기억해 시각이 1스탭 진행될 때마다 갱신. RNN의 출력 h를 은식상태 혹은 은닉상태벡터라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 BPTT\n",
    "\n",
    "- 순환 구조를 펼친 후의 RNN에는 일반적인 오차역전파법을 적용할 수 있다\n",
    "- BPTT Backpropagation Through Time 시간 방향으로 펼친 신경망의 오차역전파\n",
    "- 시계열 데이터를 학습할 때 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅 자원 증가\n",
    "- 시간 크기가 커지면 역전파 시의 기울기가 불안정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Truncated BPTT\n",
    "\n",
    "- 큰 시계열 데이터 취급할 때 신경명 연결을 적당한 길이로 끊는다\n",
    "- 시간축 방향으로 너무 길어진 신경망을 적당한 지점에서 잘라내어 작은 신경망 여러 개로 만든고 이 잘라낸 작은 신경망에서 오차역전파법을 수행\n",
    "- 순전파의 흐름은 끊어지지 않고 전파하고 역전파의 연결은 적당한 길이로 잘라, 잘라낸 신경망 단위로 학습 수행\n",
    "- 지금까지 신경망에서는 미니배치 학습을 수행할 때 데이터를 무작위로 선택해 입력하였으나 RNN에서 Truncated BPTT를 수행할 때는 데이터를 순서대로 입력해야 한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Truncated BPTT의 미니배치 학습\n",
    "- 데이터를 순서대로 제공\n",
    "- 미니배치별로 데이터를 제공하는 시작위치를 옮기기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RNN 구현\n",
    "- 길이가 T인 시계열 데이터를 받아 각 시각의 은닉 상태 T개 출력\n",
    "- 모듈화를 위해 신경망을 하나의 계층으로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.cache\n",
    "\n",
    "        dt = dt_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmult(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Time RNN 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh, = None, None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0,0,0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)  # 합산된 기울기\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 시계열 데이터 처리 계층 구현\n",
    "- RNN 사용 언어 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 RNNLM RNN Language Model 의 전체 그림\n",
    "- 첫 번째 층은 Embedding 계층. 단어 ID를 단어의 분산 표현(단어 벡터)으로 변환하여 RNN 계층으로 입력\n",
    "- RNN 계층은 은닉 상태를 다음 층으로 출력함과 동시에, 다음 시각의 RNN 계층으로 출력\n",
    "- RNN 계층이 위로 출력한 은닉 상태는 Affine 계층을 거쳐 Softmax 계층으로 전달됨\n",
    "- RNN 계층이 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 저장(기억)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Time 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 정답 레이블이 원핫 벡터인 경우\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        mask = (ts != self.ignore_label)\n",
    "\n",
    "        # 배치용과 시계열용을 정리(reshape)\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask  # ignore_label에 해당하는 데이터는 손실을 0으로 설정\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "\n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]  # ignore_label에 해당하는 데이터는 기울기를 0으로 설정\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RNNLM 학습과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 RNNLM 구현\n",
    "- RNNLM에서 사용하는 신경망을 SimpleRnnlm 클래스로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch05')\n",
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # weight initialization\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') \n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f') \n",
    "        rnn_b = np.zeros(H).astype('f') \n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astyupe('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 언어 모델의 평가\n",
    "- 언어 모델은 주어진 과거 단어(정보)로부터 다음에 출현할 단어의 확률분포를 출력\n",
    "- 언어의 예측 성능을 평가하는 척도로 퍼플렉서티(perplexity, 혼란도)를 자주 이용\n",
    "- 퍼플렉서티는 간단히 말하면 확률의 역수\n",
    "    - 예를들어 you 다음에 say가 올 확률이 0.8이라면 퍼플렉서티는 1/0.8 = 1.25\n",
    "    - 작을수록 좋은값. 이 값은 분기수(number of branches)로 해석. 위의 1.25는 다음 출현단어 후보 1개에 근접\n",
    "- 정보이론 분야에서는 퍼플렉서티를 기하평균 분기 수 라고도 한다\n",
    "- 이는 데이터가 1개일때 설명한 분기 수를 데이터가 N개인 경우에서 평균한 것이라고 해석할 수 있다\n",
    "- 입력 데이터가 여러개일 때의 퍼플렉서티<br><br>\n",
    "$L\\ =\\ \\frac{1}{N}\\sum _n^{ }\\sum _k^{ }t_{nk}\\log y_{nk}$<br><br>\n",
    "$perplexity = e^L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 RNNLM의 학습 코드\n",
    "- PTB 데이터셋 이용 RNNLM 학습 수행\n",
    "- PT 데이터셋 전부를 대상으로 학습하면 좋은 결과를 낼 수 없기 때문에 처음 1,000개 단어만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기 : 1000, 어휘 수 : 418\n",
      "| epoch 1 | perplexity 400.70\n",
      "| epoch 2 | perplexity 280.91\n",
      "| epoch 3 | perplexity 228.78\n",
      "| epoch 4 | perplexity 219.21\n",
      "| epoch 5 | perplexity 207.24\n",
      "| epoch 6 | perplexity 202.74\n",
      "| epoch 7 | perplexity 198.01\n",
      "| epoch 8 | perplexity 196.66\n",
      "| epoch 9 | perplexity 191.27\n",
      "| epoch 10 | perplexity 192.74\n",
      "| epoch 11 | perplexity 188.06\n",
      "| epoch 12 | perplexity 191.41\n",
      "| epoch 13 | perplexity 188.93\n",
      "| epoch 14 | perplexity 189.84\n",
      "| epoch 15 | perplexity 187.81\n",
      "| epoch 16 | perplexity 183.95\n",
      "| epoch 17 | perplexity 181.39\n",
      "| epoch 18 | perplexity 177.40\n",
      "| epoch 19 | perplexity 178.55\n",
      "| epoch 20 | perplexity 178.83\n",
      "| epoch 21 | perplexity 176.79\n",
      "| epoch 22 | perplexity 172.21\n",
      "| epoch 23 | perplexity 168.80\n",
      "| epoch 24 | perplexity 169.96\n",
      "| epoch 25 | perplexity 166.83\n",
      "| epoch 26 | perplexity 165.34\n",
      "| epoch 27 | perplexity 159.91\n",
      "| epoch 28 | perplexity 156.11\n",
      "| epoch 29 | perplexity 153.33\n",
      "| epoch 30 | perplexity 146.05\n",
      "| epoch 31 | perplexity 148.15\n",
      "| epoch 32 | perplexity 142.72\n",
      "| epoch 33 | perplexity 141.22\n",
      "| epoch 34 | perplexity 134.91\n",
      "| epoch 35 | perplexity 132.61\n",
      "| epoch 36 | perplexity 128.34\n",
      "| epoch 37 | perplexity 121.89\n",
      "| epoch 38 | perplexity 118.87\n",
      "| epoch 39 | perplexity 112.87\n",
      "| epoch 40 | perplexity 109.41\n",
      "| epoch 41 | perplexity 107.70\n",
      "| epoch 42 | perplexity 103.09\n",
      "| epoch 43 | perplexity 98.50\n",
      "| epoch 44 | perplexity 94.25\n",
      "| epoch 45 | perplexity 91.87\n",
      "| epoch 46 | perplexity 89.20\n",
      "| epoch 47 | perplexity 84.14\n",
      "| epoch 48 | perplexity 78.40\n",
      "| epoch 49 | perplexity 76.98\n",
      "| epoch 50 | perplexity 73.46\n",
      "| epoch 51 | perplexity 69.46\n",
      "| epoch 52 | perplexity 67.05\n",
      "| epoch 53 | perplexity 62.72\n",
      "| epoch 54 | perplexity 59.60\n",
      "| epoch 55 | perplexity 57.41\n",
      "| epoch 56 | perplexity 53.29\n",
      "| epoch 57 | perplexity 50.85\n",
      "| epoch 58 | perplexity 48.77\n",
      "| epoch 59 | perplexity 45.43\n",
      "| epoch 60 | perplexity 42.20\n",
      "| epoch 61 | perplexity 41.62\n",
      "| epoch 62 | perplexity 39.50\n",
      "| epoch 63 | perplexity 36.23\n",
      "| epoch 64 | perplexity 34.16\n",
      "| epoch 65 | perplexity 33.83\n",
      "| epoch 66 | perplexity 31.91\n",
      "| epoch 67 | perplexity 30.73\n",
      "| epoch 68 | perplexity 27.30\n",
      "| epoch 69 | perplexity 26.13\n",
      "| epoch 70 | perplexity 24.74\n",
      "| epoch 71 | perplexity 23.60\n",
      "| epoch 72 | perplexity 22.09\n",
      "| epoch 73 | perplexity 20.55\n",
      "| epoch 74 | perplexity 19.76\n",
      "| epoch 75 | perplexity 18.86\n",
      "| epoch 76 | perplexity 17.42\n",
      "| epoch 77 | perplexity 16.60\n",
      "| epoch 78 | perplexity 15.94\n",
      "| epoch 79 | perplexity 14.89\n",
      "| epoch 80 | perplexity 13.92\n",
      "| epoch 81 | perplexity 13.61\n",
      "| epoch 82 | perplexity 13.06\n",
      "| epoch 83 | perplexity 11.69\n",
      "| epoch 84 | perplexity 11.92\n",
      "| epoch 85 | perplexity 11.10\n",
      "| epoch 86 | perplexity 10.86\n",
      "| epoch 87 | perplexity 10.14\n",
      "| epoch 88 | perplexity 9.81\n",
      "| epoch 89 | perplexity 9.33\n",
      "| epoch 90 | perplexity 8.66\n",
      "| epoch 91 | perplexity 8.65\n",
      "| epoch 92 | perplexity 7.70\n",
      "| epoch 93 | perplexity 7.54\n",
      "| epoch 94 | perplexity 7.12\n",
      "| epoch 95 | perplexity 6.79\n",
      "| epoch 96 | perplexity 6.24\n",
      "| epoch 97 | perplexity 5.91\n",
      "| epoch 98 | perplexity 5.80\n",
      "| epoch 99 | perplexity 5.55\n",
      "| epoch 100 | perplexity 5.28\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch05')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100   # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5       # Truncated BPTT 가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습데이터 읽기 (전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]    # 입력\n",
    "ts = corpus[1:]     # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기 : %d, 어휘 수 : %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 1.각 미니매치에서 샘플을 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 2.미니배치 획득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 3.에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f' % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본적으로 신경망 학습과 거의 유사. 다만 큰 관점에서 데이터 제공방법과 퍼플렉서티 계산이 다름\n",
    "- 데이터 제공방법 : Truncated BPTT 방식으로 학습 수행\n",
    "    - 1.에서 각 미니배치가 데이터를 읽기 시작하는 위치를 계산해 offsets에 저장\n",
    "    - 2.에서는 데이터를 순차적으로 읽는다. batch_x와 batch_t 준비, time_idx를 순차적으로 늘리며 말뭉치에서 time_idx 위치 데이터를 얻는다\n",
    "    - 여기에 offsets를 이용 각 미니배치에서 오프셋 추가\n",
    "    - 또한 말뭉치를 읽는 위치가 말뭉치 크기를 넘어설 경우 말뭉치 크기로 나눈 인덱스 사용하여 처음으로 돌아온다\n",
    "    - 3.에서는 에폭마다 손실의 평균을 구하고 그 값을 사용해 퍼플렉 서티를 구한다\n",
    "- 학습을 진행할수록 퍼플렉서티가 순조롭게 낮아짐을 알수 있지만 실제로 현재의 모델로는 큰 말뭉치에 대응할 수 없다\n",
    "- 이 문제는 다음장에서 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 RNNLM의 Trainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 417.67\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 364.67\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 246.50\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 215.46\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 206.98\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 206.07\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 199.06\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.29\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 193.53\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.83\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.05\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 188.41\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.63\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 186.21\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 185.45\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.15\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.27\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 183.00\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 177.85\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 178.66\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 175.33\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 174.37\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 173.19\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 169.31\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 162.83\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 163.87\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 162.77\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 161.34\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 154.98\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 151.30\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 148.20\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 141.88\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 140.45\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 138.05\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 132.31\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 131.03\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 127.54\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 119.98\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 116.09\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 111.59\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 105.46\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 102.47\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 98.54\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 94.25\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 88.36\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 84.89\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 84.40\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 80.75\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 75.59\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 71.13\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 67.92\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 65.16\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 62.75\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 57.88\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 54.85\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 51.91\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 51.44\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 47.90\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 45.43\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 43.10\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 39.71\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 38.27\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 37.22\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 34.86\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 31.61\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 30.70\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 29.48\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 27.88\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 26.34\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 24.86\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 23.31\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 21.91\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 21.63\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 19.16\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 18.27\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 17.84\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 17.18\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 15.51\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 14.85\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 13.97\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 13.29\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 12.27\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 11.98\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 11.61\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 10.45\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.92\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.51\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.28\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 9.43\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 8.35\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.80\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.60\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.32\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 7.18\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.41\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.36\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 6.19\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 5.67\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 5.43\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 5.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3yU5Z338c9vZnI+EkIgJJEggqIIWDkoWlutXa2yYru1pdt62Npat3Zbt3a3ut3u08P2eey22+O2tqitWl0tWqrUtraKWg9FMCioIEjkGEASAiEh58Pv+WPuhBEJBslkkpnv+/XKKzPX3DP5XaD5ct3XfV+XuTsiIiIAoUQXICIiw4dCQURE+igURESkj0JBRET6KBRERKRPJNEFHIvi4mKvrKxMdBkiIiPKqlWr9rj7mMO9NqJDobKykqqqqkSXISIyopjZ1v5e0+kjERHpo1AQEZE+CgUREemjUBARkT4KBRER6aNQEBGRPgoFERHpk5KhsKOhle/9eQNb65sTXYqIyLCSkqHQ0NLBjx6v5pUdjYkuRURkWEnJUCgvzAZgR0NLgisRERleUjIU8rMi5GZE2LGvNdGliIgMKykZCmZGWWEWOxraEl2KiMiwkpKhAFA2KosdDRopiIjESt1QKMxixz7NKYiIxIp7KJhZ2MxeNLOHg+dFZvaomW0Mvo+KOfYmM6s2sw1mdkE86yoblUVjWxdNbZ3x/DEiIiPKUIwUvgC8GvP8RmCZu08GlgXPMbOTgYXAKcCFwE/NLByvosoKswB0CklEJEZcQ8HMyoGLgdtimhcAdwaP7wQujWm/z93b3X0zUA3MiVdtZaOCUNAVSCIifeI9UvgB8K9AT0zbWHffBRB8Lwnay4DtMcfVBG1vYmbXmFmVmVXV1dW948LKNVIQEXmLuIWCmc0Hat191UDfcpg2f0uD+yJ3n+Xus8aMOewWowNSnJtBejikkYKISIx47tF8FnCJmV0EZAL5ZnY3sNvMSt19l5mVArXB8TVARcz7y4Gd8SouFDLGF2ZSo5GCiEifuI0U3P0mdy9390qiE8iPu/sngKXAlcFhVwIPBY+XAgvNLMPMJgKTgZXxqg+CexU0UhAR6ZOI+xRuBt5vZhuB9wfPcfe1wGJgHfAIcJ27d8ezkOhdzQoFEZFe8Tx91MfdnwSeDB7XA+/r57hvAd8aipoAygqzqWtqp62zm8y0uF39KiIyYqTsHc1w8LLUXfu1BpKICKR6KBTqXgURkVgpHQrlvTewaV8FEREgxUNhXEEmIdNIQUSkV0qHQlo4xNj8TO2rICISSOlQgN7LUnX6SEQEFArabEdEJIZCoTCLXQ1tdPe8ZZklEZGUo1AYlUVXj1PbpHkFERGFgu5VEBHpk/KhcPBeBYWCiEjKh0JBVjoAjW1dCa5ERCTxUj4U8jKjawIeUCiIiCgUMiIhIiHjQHtnoksREUm4lA8FMyM3M6KRgogICgUAcjMiNLUrFEREFApEQ0EjBRERhQIQnWw+oJGCiIhCASAnI0KzQkFERKEAmlMQEemlUCA4faQ5BRERhQIEE80aKYiIKBQAcjPSaOno1vLZIpLyFApAbu9SFxotiEiKUygAeRkKBRERUCgAMSMFTTaLSIpTKBC9TwHQongikvIUCkSvPgJo0khBRFKcQoGDeyo0t3cnuBIRkcRSKHBwpKDTRyKS6hQKHJxo1ukjEUl1CgUgJ12XpIqIgEIBgHDIyEkP65JUEUl5CoVArvZUEBFRKPTK0fLZIiIKhV552pJTRESh0Eunj0REFAp9cjVSEBFRKPTKzUjTSEFEUl7cQsHMMs1spZmtMbO1Zvb1oL3IzB41s43B91Ex77nJzKrNbIOZXRCv2g4nT6ePRETiOlJoB85z9xnATOBCMzsDuBFY5u6TgWXBc8zsZGAhcApwIfBTMwvHsb436d2S0127r4lI6opbKHjUgeBpWvDlwALgzqD9TuDS4PEC4D53b3f3zUA1MCde9R0qNzNCd4/T1tkzVD9SRGTYieucgpmFzWw1UAs86u4rgLHuvgsg+F4SHF4GbI95e03QduhnXmNmVWZWVVdXN2i19u6p0KRF8UQkhcU1FNy9291nAuXAHDObdoTD7XAfcZjPXOTus9x91pgxYwar1INbcuoKJBFJYUNy9ZG7NwBPEp0r2G1mpQDB99rgsBqgIuZt5cDOoagPYpfPViiISOqK59VHY8ysMHicBZwPrAeWAlcGh10JPBQ8XgosNLMMM5sITAZWxqu+Q2mfZhERiMTxs0uBO4MriELAYnd/2MyWA4vN7GpgG3AZgLuvNbPFwDqgC7jO3YdsK7S+LTk1UhCRFBa3UHD3l4DTDtNeD7yvn/d8C/hWvGo6kjyNFEREdEdzr96RQnOHQkFEUpdCIaAtOUVEFAp9MiJh0sMhXX0kIilNoRAjJ0NbcopIalMoxNCeCiKS6hQKMXIz0jSnICIpTaEQIy8jwgGtfSQiKUyhEEOnj0Qk1SkUYmhLThFJdQqFGBopiEiqUyjEyMtQKIhIalMoxMjJiNDW2UNnt3ZfE5HUpFCI0bf+kUYLIpKiFAoxtP6RiKQ6hUKMPO2+JiIpTqEQo2/3NYWCiKQohUKMvn2adfpIRFKUQiFG7+5r2pJTRFKVQiFGbkYaoJGCiKQuhUKMwuw0zGB3Y1uiSxERSQiFQozMtDAnjMnl5R37E12KiEhCKBQOMb28kJdqGnD3RJciIjLkFAqHmFFRwJ4DHezcr1NIIpJ6FAqHOLWsAICXaxoSXImIyNCLDOQgM/uPtzmk1t1/Ngj1JNzU0nwiIWNNzX4unFaa6HJERIbUgEIBOANYCFg/r98JJEUoZKaFOak0j5c0UhCRFDTQUOh298b+XjSzpJqVnV5eyO/W7KSnxwmF+stBEZHkM9A5hbf7pZ9UoTCjvICmti621DcnuhQRkSE10JFCmpnl9/OaAeFBqmdYmF5eCMBLNfs5fkxugqsRERk6Aw2F54Drj/D6HwehlmFjckkumWkhXqrZz6WnlSW6HBGRITPQUID+J5mTTiQcYtr4Ak02i0jKGWgozCVFrj7qdWp5Afeu3EZXdw+RsG7nEJHUMNDfdt3u3uju+w/3RZJNNAPMKC+krbOHjbUHEl2KiMiQ0dVH/ZheHr2zec12nUISkdQx0FBIM7P8fr4KSLKrjwAqR+dwXFE2//NENftbOhNdjojIkNDVR/0IhYwfLpzJR36+nBvuX8OtV5yOWcrMtYtIijqaGVQ7wldSOu24Udz0gak89upubnt6c6LLERGJO1199Db+4axKVm7ey7cfWY8ZnDQun8ribMoKszRyEJGkE7e1j8ysArgLGAf0AIvc/YdmVgT8GqgEtgAfcfd9wXtuAq4GuoHPu/ufBt6V+DAzvv3h6XzkZ8v5z9+/2tf+niljWHTF6WREkm46RURS2EBD4Z1cfdQF3ODuL5hZHrDKzB4FrgKWufvNZnYjcCPwZTM7meho5BRgPPCYmU1x9+4B1hg3BVlp/PEL72Z3Uxtb9rSwcvNevv/Ya3zx12v40cdOI6xF80QkScRt7SN33wXsCh43mdmrQBmwAHhvcNidwJPAl4P2+9y9HdhsZtXAHGD5AGuMq1DIKC3IorQgizMnjSYrPcT//cN6inLS+caCU+jsdjbWNlGSl8mYvIxElysi8o4MydVHZlYJnAasAMYGgYG77zKzkuCwsuDn9KoJ2oala86ZRH1zBz//yyaerd7D9n0tdHY7eZkR7v30GUwLdnATERlJ4n71kZnlAr8Brj/SvEQ/n3O4uYprzKzKzKrq6uoGWntc3HjhSfzTeSdQXpTN1Wcfz39fNoO8jAhX/GIl1bVNCa1NROSdiOvVR2aWRjQQ7nH3JUHzbjMrDUYJpUBt0F4DVMS8vRzYeehnuvsiYBHArFmzEnontZlxw9+c+Ka2d00YxWU/W87Hb1vB/Z+Zx3GjsxNUnYjI0Yvb2kcWvV7zduBVd/9ezEtLgSuDx1cCD8W0LzSzDDObCEwGVr6TTiXSxOIc7v7UHNq7evjQLX/lgVU19PQc/OPZ2dDKqq37cH/zH5m709imO6dFJLHiefXRWcDlwMtmtjpo+zfgZmCxmV0NbAMuA3D3tWa2GFhH9Mql64bDlUfvxEnj8rn302dw05KX+dL9a/jV8i1cPL2UR9ft5vkt+wCYM7GI/5h/MtPKClj+ej3ff+w1nt+yl3+94CSufc/xugdCRBLCDv0X62EPMvsj8NH+XgbucvcFg1nYQMyaNcurqqqG+scOWE+P8+DqHXz7kfXsbmxnckkul8wYT35WGj9atpG9LR1MKcljw+4mSvIymDI2j2eq93DZ6eV864Onkh45OJDr7nHur9rOz5/axPjCTM49sYT3TR3LxOKcBPZQREYiM1vl7rMO+9oAQ+H/0P9owYDd7j7kdzQP91Do1drRzZ4D7VQUHZxfaGzr5CePV/P0xj18+PRy/n7ucaSHQ/xg2UZ+tGwjsytHMX/6eMYXZmHA9x97jbU7G5lRXkBzRzfVwZLeF5wylm9eOo2SvMwE9U5ERprBCIU/8DYTze5+6Tsv8Z0ZKaFwtB58cQdfffAVmtq7+trGF2Ry00VTmT+9FDNj+94WHnxxBz9+oprs9DBfv+QULpkxXqedRORtDUYo/M7d//YIr//W3T94DDW+I8kaChA99VTf3MHOhlb2NndwxvGjyUp/65Ia1bUH+JcH1vDitgYWzBzPzR+aftjjRER6HSkU4jnRLMcgFDLG5GW87d3RJ5Tk8sC18/jpE9V877HX2Lj7AIuuOJ3yUboUVkSOXtyWuZChEw4Z//S+yUwrL+Dz977IJf/zLOdPLWFHQys1+1qZWJzD9edPYWZFYaJLFZFh7mgnmvs7YV3r7rcMZmEDkcynj96pzXua+cJ9L7KzoY2KoizGF2ax/PV69jZ38P6Tx3LFmROYXJLH2PwMzT+IpKhjnlMYrhQKA3OgvYtfPrOZRU9voqktOnmdnR5m0phcppbmMbU0n7kTR3Py+P4GgyKSTBQKAkQvg325Zj+b6g7wel0z1bUHeHVXI/XNHQBcdno5N37gJEbnapVXkWQ2GBPNkgTyM9M464RizjqhuK/N3altaueOv27h1qc28ae1b/BvF01l4ZzjElipiCTK0aySKknIzBibn8mXLzyJR65/N6eML+DGJS/zo2UbE12aiCSAQkH6nFCSx92fmsuH3lXG9x59jZ88UZ3okkRkiOn0kbxJOGR858MzcIfv/GkDdU3tZKeH2Vh7gNqmdipHZzNlbB4njctjRkUhxZp/EEkqCgV5i3DI+O5lM+hx546/biESMiqLcyjJy6Bqyz4eWn1wm4vjirKZXVnEly6YQmlBVgKrFpHBoKuPpF/uzq79bYzJyyAtfPBMY2NbJ+t3NfHitn28uK2BpzbWUZybwb3XnEFZoYJBZLjTJakSV6u3N3D57SsozE7j3k+foSU2RIa5I4WCJprlmM2sKOTuq+fS0NLJwkXPsW7nkbbiFpHhTKEgg2JGRSH3fGourR3dzP/x09y05GX2HGhPdFkicpQUCjJoppcX8vgN7+WqeRO5v2o7537nSX742Eb2t2jvaZGRQnMKEhfVtQf49iPreXTdbnIzIlxx5gQ+855JFGSlJbo0kZSnOQUZcieU5HLrFbP4w+ffzXtOHMMtf3mdj/58OfU6pSQyrCkUJK5OHp/PT/7+Xfzqk3PZUt/Mx259jromBYPIcKVQkCFx9uRifnHVbLbvbWXhouWsf6ORkXzqUiRZaU5BhtSKTfX8wx3P09LRTUFWGu86rpBzpoxhwcwyinLSE12eSErQzWsyrOxsaOXpjXW8sLWBqq17eb2umbSwce6JJVxzzvHMqixKdIkiSU2hIMPa+jca+c2qGn774g4aWjr5zmXT+eBp5YkuSyRp6eojGdZOGpfPVy4+mce/9F5mVxbxz79ew8//8rrmHEQSQKukyrCRn5nGHZ+czRcXr+H//XE9L2zbx7xJxZxaXsDJpflkpoUTXaJI0lMoyLCSEQnz44WnMaEom18/v50/rd0NQGF2Gp879wQuP3MCGRGFg0i8aE5Bhq3epbtfqtnPPSu28vTGPZQVZvGVi6dy0amliS5PZMTSnIKMSGbG+MIsLpw2jl9dPZe7r55LYXYan73nBR5+aefbf4CIHDWFgowYZ08uZsln5zG7chRfXLyGF7btS3RJIklHoSAjSkYkzM8vn8W4/EyuuauK7XtbEl2SSFJRKMiIU5STzi+umk17Vw9X/XIlr+zYn+iSRJKGQkFGpBNKcll0+Sz2t3Zyyf88w9eWrqWxTfs2iBwrhYKMWGdOGs2yG97LJ86YwJ3Lt3Ded//C4+t3J7oskRFNoSAjWkFWGt9YMI2l151NcW46n7yjin9/8GVaO7oTXZrIiKRQkKRwankBD33uLK4553jufm4bF//4abbWNye6LJERR6EgSSMjEubfLprK/35qLvuaO7jsZ8vZuLsp0WWJjCgKBUk6804o5r5rzsSBjy56jrU7dXWSyEDFLRTM7BdmVmtmr8S0FZnZo2a2Mfg+Kua1m8ys2sw2mNkF8apLUsOJ4/JY/JkzyYyEWLjoOW5/ZjPN7V2JLktk2IvnSOEO4MJD2m4Elrn7ZGBZ8BwzOxlYCJwSvOenZqZVz+SYTCzOYfG1ZzK1NJ9vPryOeTc/zvf+vEGXroocQdxCwd2fAvYe0rwAuDN4fCdwaUz7fe7e7u6bgWpgTrxqk9RRPiqbxZ85k9/84zzmTCziR49X877//gsPrd6h/RpEDmOo5xTGuvsugOB7SdBeBmyPOa4maBMZFKdPGMWtV8zid587m9KCTL5w32ouv32lrlASOcRwmWi2w7Qd9p9xZnaNmVWZWVVdXV2cy5Jkc2p5Ab/97Fl8c8EprNnewIU/eJo7nt1MT49GDSIw9KGw28xKAYLvtUF7DVARc1w5cNi1kd19kbvPcvdZY8aMiWuxkpzCIePyMyv58xfPYe7xRXztd+v42K3PsaOhNdGliSTcUIfCUuDK4PGVwEMx7QvNLMPMJgKTgZVDXJukmNKCLH551Wz+6++ms3ZnI3/307/ymu5rkBQXz0tS7wWWAyeaWY2ZXQ3cDLzfzDYC7w+e4+5rgcXAOuAR4Dp31zoFEndmxkdmV/DAP55JjzuX/Wy59mmQlKbtOEUC2/e28InbV1Db2M63PjiNS2eWEQodbrpLZGTTdpwiA1BRlM0D187jxHF5fHHxGi75yTM8s3FPossSGVIaKYgcoqfHWbpmJ9/98wZq9rUyOiedopx0RmWnM2diEZ95z/HkZaYlukyRd+xIIwWFgkg/2ru6WVxVw7qdjTS0dFDX1E7V1n0U56bzpb85kctmVRDW6SUZgY4UCpGhLkZkpMiIhLn8jAlvaluzvYFvPLyOG5e8zK+rtnPLx09nXEFmgioUGXyaUxA5CjMqCnng2jP5wUdn8tobTcz/8TNUbTl0NReRkUuhIHKUzIxLTyvjt9edRW5GmI/d+hy/em6r1lKSpKBQEHmHpozN46HrzmbepGK++uArfPquKuqa2hNdlsgxUSiIHIOC7DR+edVsvjr/ZJ7auIcLf/AUf3x5l0YNMmIpFESOUShkXH32RB7+p7MZm5/JP97zApf+5FmeWF+rcJARR6EgMkimjM3joc+dxbf/7lTqmzv4hzueZ8FPnuWh1Tvo6OpJdHkiA6L7FETioKOrhyUv1LDoqU1s2tPMmLwMPj73OC6bVUFZYVaiy5MUp5vXRBKkp8d5amMdd/x1C09uqMMM5k0azUdmVfC308drbSVJCIWCyDCwfW8Lv3mhhgdW1VCzr5Xzp5bw3ctmUJidnujSJMVoQTyRYaCiKJvrz5/CU/9yLl/725P5y2t1XPyjZ1i9vSHRpYn0USiIDLFQyLjqrIncf+08AD58y1+58TcvsXmP9ouWxFMoiCTIzIpCfv/5s1k4p4IlL+7gvP9+kuvueYGXa/YnujRJYZpTEBkGapva+OWzW7h7+Vaa2ruYN2k0nz7neKaXFVCQlUYkrH+/yeDRRLPICNHY1sm9K7bxi2c3s7vx4JIZhdlpzJ9eyvXnT6E4NyOBFUoyUCiIjDAdXT08saGWXQ2tNLR2sq2+haVrdpIRCXHteybxybMnkpOhle/lnVEoiCSBTXUH+PYj6/nT2t1kp4eZP72Uj8yq4PQJozDT/Q4ycAoFkSSyensD/7tiKw+/tIuWjm4mFufwwdPK+OBpZVQUZSe6PBkBFAoiSai5vYvfv7yLJS/U8Nym6EY/75kyhn+54ESmlRUkuDoZzhQKIkluR0MrS1bVcPuzm2lo6eTiU0v51LsnMq2sgDRduSSHUCiIpIjGtk5ufWoTtz+zmZaObjLTQkwvL2R6WQFTxuYxeWwuU8bmaZI6xSkURFLM3uYOlr9ez6qt+1i1bR/rdzXSHizfnREJ8TenjOND7yrj3ScU6x6IFKRQEElx3T3O9r0tvLa7iWeq97B0zU4aWjoZl5/JZ8+dxEdnV5ARCSe6TBkiCgUReZOOrh4eX1/L7c9s4vkt+xhfkMknz57IKeMLqCzOZmxeppb1TmIKBRE5LHfnmeo9fP/R13hh28HVWrPSwpxUmscp4/M5tayA2ZVFTCzO0f0QSUKhICJH5O7saGhly54WttQ3U117gHW7Gnl1ZyNN7V0AlORlMPf40cyZWMScyiIml+RqNDFCHSkUdAmCiGBmlI/KpnxUNmdPLu5r7+lxNtc3s2LTXp7bVM+KzfX8bs1OILoe0+nHjeL0ylHMrizi1LICMtM0LzHSKRREpF+hkDFpTC6TxuTy93OPw93ZtreFlZv38vyWvVRt3cey9bUApEdCzKwoZO7EIt41YRSnVRRqV7kRSKEgIgNmZkwYncOE0TlcNqsCiF7+umrrPlZurmfl5r389MnX6e6JnpY+vjiH8YVZZKWHyU4Pc2pZAZeeVqaVXocxzSmIyKA60N7FSzUNrN7ewOptDew50E5LRzcH2ruo2ddKJGScP3Us500tYWJxDhOKshmTl6FJ7CGkOQURGTK5GRHmTSpm3qTit7z22u4m7q/azpIXdvDI2jf62sMhIz8zQkFWGkU56YzNz2RsfiYTRmdzxvGjOXFsnia1h4hGCiIy5Lq6e6jZ18qW+ma27W1hd2Mb+1s72d/axd7mdnY3trN7f1vflU+jc9I5fcIoxhdmMTY/k3EFGRxXlMOE0dmMzknXKOMoaaQgIsNKJByisjiHyuKcIx63o6GV5a/X89fqPaypaWD56/V9QdErOz3MuIJMxuVnMq4gk+OLczihJDo5XpCdRnZ6hOy0sEYaA6SRgoiMKM3tXeza38a2vc1srW/pG2m8sb+NnQ1tvNHYdtj35aSHyc2MkJeZRuXobKaW5nPSuHzKRmUxOied0bnpZKenxr+TNVIQkaSRkxHhhJJcTijJPezrB9q72FR3gM17mmlq66Klo4vm9uhE94G2LhpaO9hU18wTG+r6rpLqlR4JkZ+ZRkFWhJyMCJmRMBlpIUJmdHb30NndQ1Z6hMkluUwZm8vE4lyKc9MpzssgLyOSFKexFAoiklRyMyLR5cLLC494XFtnN9W1B9jd2EZ9cwf1BzqCeY1OGls7aenoorWzm6a2Ltyd9EiItHCI+gPtrNhU37fqbK9wyMiIhIKv6CW4WelhstLCpIVDpEVCZEZCjCvIpKwwi3EFmWREQpgZITPSwkZ6OER6JERBVhqjczMozEob8tNewy4UzOxC4IdAGLjN3W9OcEkikoQy08JMKyt4R7vU9a46u21vC/XN7dQf6KChpZP2rm7au3po6+ymtbOH1o4uWjq66ep2Wls72d3RzXOb6mls63r7HwKEDLLTI2SmhcgMwsUAMzj3xBL+ff7JR1372xlWoWBmYeAnwPuBGuB5M1vq7usSW5mIyEHhkA1oorw/TW2d7G5so7Pb6XGnpwc6gtNT7V09NLR0sLe5g33NHTR3dNPa2U1bRzddPdHjHSgtzBrcTgWGVSgAc4Bqd98EYGb3AQsAhYKIJI28zDTyMtMSXcZhDbctl8qA7THPa4K2PmZ2jZlVmVlVXV3dkBYnIpLshlsoHG5G5U2XB7j7Inef5e6zxowZM0RliYikhuEWCjVARczzcmBngmoREUk5wy0Ungcmm9lEM0sHFgJLE1yTiEjKGFYTze7eZWafA/5E9JLUX7j72gSXJSKSMoZVKAC4+x+APyS6DhGRVDTcTh+JiEgCKRRERKTPiF4l1czqgK3H8BHFwJ5BKmekSMU+Q2r2W31OHUfb7wnufthr+kd0KBwrM6vqb/nYZJWKfYbU7Lf6nDoGs986fSQiIn0UCiIi0ifVQ2FRogtIgFTsM6Rmv9Xn1DFo/U7pOQUREXmzVB8piIhIDIWCiIj0SclQMLMLzWyDmVWb2Y2JricezKzCzJ4ws1fNbK2ZfSFoLzKzR81sY/B9VKJrjQczC5vZi2b2cPA8qfttZoVm9oCZrQ/+zs9M9j4DmNk/B/99v2Jm95pZZjL228x+YWa1ZvZKTFu//TSzm4LfbxvM7IKj+VkpFwoxW35+ADgZ+JiZDf5Gp4nXBdzg7lOBM4Drgn7eCCxz98nAsuB5MvoC8GrM82Tv9w+BR9z9JGAG0b4ndZ/NrAz4PDDL3acRXURzIcnZ7zuACw9pO2w/g//PFwKnBO/5afB7b0BSLhSI2fLT3TuA3i0/k4q773L3F4LHTUR/SZQR7eudwWF3ApcmpsL4MbNy4GLgtpjmpO23meUD5wC3A7h7h7s3kMR9jhEBsswsAmQT3X8l6frt7k8Bew9p7q+fC4D73L3d3TcD1UR/7w1IKobC2275mWzMrBI4DVgBjHX3XRANDqAkcZXFzQ+AfwV6YtqSud/HA3XAL4NTZreZWQ7J3WfcfQfwXWAbsAvY7+5/Jsn7HaO/fh7T77hUDIW33fIzmZhZLvAb4Hp3b0x0PfFmZvOBWndflehahlAEeBdwi7ufBjSTHKdMjig4h74AmAiMB3LM7BOJrWpYOKbfcakYCimz5aeZpRENhHvcfUnQvNvMSoPXS4HaRNUXJ2cBl5jZFqKnBs8zs7tJ7n7XACu+nGkAAANPSURBVDXuviJ4/gDRkEjmPgOcD2x29zp37wSWAPNI/n736q+fx/Q7LhVDISW2/DQzI3qO+VV3/17MS0uBK4PHVwIPDXVt8eTuN7l7ubtXEv27fdzdP0ES99vd3wC2m9mJQdP7gHUkcZ8D24AzzCw7+O/9fUTnzpK937366+dSYKGZZZjZRGAysHLAn+ruKfcFXAS8BrwOfCXR9cSpj2cTHTK+BKwOvi4CRhO9UmFj8L0o0bXG8c/gvcDDweOk7jcwE6gK/r4fBEYle5+Dfn8dWA+8AvwKyEjGfgP3Ep036SQ6Erj6SP0EvhL8ftsAfOBofpaWuRARkT6pePpIRET6oVAQEZE+CgUREemjUBARkT4KBRER6aNQEBkEFvV4sA5Rf8fMNLPlwaqeL5nZR2Nem2hmK4IVL38d3EODmc03s68PRR9EQDuviQBgZl8juppsV9AUAZ4LHr+l3d2/dsj7LwbOd/d/PsLPmAK4u280s/HAKmCquzeY2WJgibvfZ2Y/A9a4+y3BTVkvAGe5e8tg9FXkSDRSEDloobvPd/f5RO+Gfrv2WB8nuKPUzGYHI4FMM8sJRgbT3P01d98I4O47iS5LMCb4xX8e0eUpIGbFS4/+q+1JYP7gdlXk8BQKIoPjLKL/8sfdnye61MB/Av8F3O3ur8QebGZzgHSid52OBhrcvXc0cuiqllXAu+NavUggkugCRJJEkUf3rej1DaLrbLUR3QimT7B42a+AK929JxgpHCr2vG4t0VVAReJOIwWRwdFlZrH/PxUBuUAekNnbGExE/x74d3fvnbPYAxQGG8XAW1e1zARa41W4SCyFgsjg2EB0s5tei4CvAvcA3wYIrij6LXCXu9/fe2Awb/AE8OGg6dCVPacQXfBNJO4UCiKD4/dEV2XFzK4Autz9f4Gbgdlmdh7wEaLbZl5lZquDr5nB+78MfNHMqonOMdwe89nnBp8vEneaUxAZHLcBdwG3uftdwWPcvRuYG3Pc3Yd7s7tv4jD76JrZWCDL3V8e9IpFDkOhIBJVC9xlZr37OoeAR4LH/bX3cfddZnarmeX74G57ehxwwyB+nsgR6eY1ERHpozkFERHpo1AQEZE+CgUREemjUBARkT4KBRER6fP/AYfsKxAx6SO4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chap05/train.py\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch05')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5  # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]  # 출력（정답 레이블）\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 정리\n",
    "- RNN은 순환하는 경로가 있고, 이를 통해 내부에 은닉상태를 기억할 수 있다\n",
    "- RNN의 순환 경로를 펼침으로써 다수의 RNN계층이 연결된 신경망으로 해석할 수 있으며, 보통의 오차역전파법으로 학습할 수 있다(=BPTT)\n",
    "- 긴 시계열 데이터를 학습할 때는 데이터를 적당한 길이씩 모으고(블록), 블록단위로 BPTT에 의한 학습을 수행한다(=Truncated BPTT)\n",
    "- Truncated BPTT에서는 역전파의 연결만 끊고, 순전파의 연결을 유지하기 위해 데이터를 순차적으로 입력\n",
    "- 언어 모델은 단어 시퀀스를 확률로 해석\n",
    "- RNN 계층을 이용한 조건부 언어모델은 그때까지 등장한 모든 단어의 정보를 기억할 수 있다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e7d24ecb1dc1117e8330ee9e498b85da846e4ffb1348d12e4a7f0695b68a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
