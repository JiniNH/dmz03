{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter6. 게이트가 추가된 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. RNN의 문제점\n",
    "- RNN은 시계열 데이터의 장기 의존 관계를 학습하기 어렵다\n",
    "- 그 원인은 BPTT에서 기울기 소실 혹은 기울기 폭발이 일어나기 때문이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 RNN 복습\n",
    "\n",
    "- RNN 계층은 순환 경로를 갖고 있다\n",
    "- 시계열 데이터인 xt를 입력하면 ht를 출력한다\n",
    "- 이 ht는 RNN 계층의 은닉상태라고 하여, 과거의 정보를 저장한다\n",
    "- 이전 시각의 은닉 상태를 이용하여 과거정보를 계승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 기울기 소실 또는 기울기 폭발\n",
    "- RNN계층이 과거 방향으로 의미 있는 기울기를 전달함으로써 시간 방향의 의존관계를 학습할 수 있다\n",
    "- 기울기는 학습해야 할 의미가 있는 정보가 들어 있고, 그것을 과거로 전달함으로써 장기 의존 관계를 학습한다\n",
    "- 하지만 기울기가 중간에 사그라들면 가중치 매개변수는 전혀 갱신되지 않고 장기 의존관계를 학습할 수 없다\n",
    "- 현재의 단순한 RNN계층에서는 시간을 거슬러 올라갈수록 기울기가 작아지거나(기울기 소실) 혹은 커질 수 있으며(기울기 폭발), 대부분 둘 중 하나의 운명을 걷게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 기울기 소실과 기울기 폭발의 원인\n",
    "- 역전파로 전해지는 기울기는 차례로 tanh, +, MatMul 연산을 통과한다\n",
    "- \\+ 의 역전파는 상류에서 전해지는 기울기를 그대로 하류로 흘려보낼 뿐 기울기가 변하지는 않는다\n",
    "\n",
    "$\\text{hyperoic} \\text{tangent} y=tanh \\left(x\\right)=\\cfrac{e^x-e^{-x}}{e^x+e^{-x}}$  \n",
    "\n",
    "분수 함수의 미분공식$\\{ \\cfrac{f(x)}{g(x)} \\}^{'} = \\cfrac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$\n",
    "\n",
    "$\\cfrac{\\partial e^x}{\\partial x}=e^x, \\;\\; \\cfrac{\\partial e^{-x}}{\\partial x}=-e^{-x} \\;\\;를\\; 이용하여$\n",
    "\n",
    "$\\cfrac{\\partial \\tanh \\left(x\\right)}{\\partial x}\\ =\\ \\cfrac{\\left(e^x+e^{-x}\\right)\\left(e^x+e^{-x}\\right)-\\left(e^x-e^{-x}\\right)\\left(e^x-e^{-x}\\right)}{\\left(e^x+e^{-x}\\right)^2}$\n",
    "\n",
    "$=1-\\cfrac{\\left(e^x-e^{-x}\\right)^2}{\\left(e^x+e^{-x}\\right)^2}\\ =\\ 1-\\tanh \\left(x\\right)^2\\ =\\ 1-y^2$\n",
    "\n",
    "- tanh(x)의 미분값은 1.0 이하이고 0에서 멀어질수록 작아진다. 달리 말하면, 역전파에서는 기울기가 tanh 노드를 지날 때마다 값이 계속 작아진다는 뜻이다\n",
    "- RNN 계층의 활성화 함수로는 주로 tanh 함수를 사용하는데 이를 ReLU로 바꾸면 기울기 소실을 줄일 수 있다\n",
    "- MatMul 기울기의 크기는 시간에 비례해 지수적으로 증가(기울기 폭팔)하거나 감소(기울기 소실) 한다. 행렬 Wh를 T번 반복해서 곱했기 때문이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fad70adf70>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-10, 10)\n",
    "y1 = np.tanh(x)\n",
    "y2 = 1 - np.tanh(x) ** 2\n",
    "\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2, ':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 기울기 폭발 대책\n",
    "- 기울기 폭발의 대책으로 전통적인 기울기 클리핑 gradients clipping 기법이 있다\n",
    "- 신경망에서 사용되는 모든 매개변수에 대한 기울기를 하나로 처리한다고 가정(g-hat)하고 문턱값을 초과하면 두 번째 줄의 수식과 같이 기울기를 수정한다\n",
    "\n",
    "$if\\ \\mid \\mid \\hat{g}\\mid \\mid \\ge threshold:$\n",
    "\n",
    "$\\ \\ \\ \\ \\hat{g}\\ =\\ \\cfrac{threshold}{\\mid \\mid \\hat{g}\\mid \\mid }\\hat{g}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 클리핑 구현\n",
    "import numpy as np\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 기울기 소실과 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 LSTM의 인터페이스\n",
    "- LSTM 계층의 인터페이스에 c(기억 셀, memory cell) 라는 LSTM 전용의 기억메커니즘이 있다\n",
    "- 기억 셀의 특징은 데이터를 자기 자신으로만(LSTM 계층 내에서만) 주고받는다는 것이다. LSTM 계층 내에서만 완결되고, 다른 계층으로는 출력하지 않는다\n",
    "- 반면, LSTM의 은닉상태 h는 RNN 계층과 마찬가지로 다른 계층으로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 LSTM 계층 조립하기\n",
    "- LSTM의 기억 셀 c_t에는 시각 t에서의 LSTM 기억이 과거부터 시각 t까지 모든 정보가 저장\n",
    "- 필요한 정보를 모두 간직한 이 기억을 바탕으로, 외부 계층과 다음 시각의 LSTM에 은닉 상태 h_t 출력\n",
    "- 기억 셀 c_t는 3개의 입력(c_t-1, h_t-1, x_t)으로부터 어떤 계산을 수행하여 계산하고 갱신된 c_t에 tanh함수를 적용해 h_t를 계산한다\n",
    "- LSTM의 게이트는 열기/닫기 뿐 아니라 어느 정도(열림 상태, openness, 0.0~1.0) 열지를 조절\n",
    "- 열림 상태를 제어를 위해 전용 가중치 매개변수를 이용, 이 가중치 매개변수는 학습 데이터로부터 갱신된다. 게이트의 열림 상태를 구할때는 시그모이드 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 output 게이트\n",
    "- tanh(c_t)에 게이트를 적용.\n",
    "- tanh(c_t)의 각 원소에 대해 그것이 다음 시각의 은닉 상태에 얼마나 중요한가를 조정한다.\n",
    "- 이 게이트는 다음 은닉 상태 h_t의 출력을 담당하는 게이트로 output 게이트 라고 한다\n",
    "- ouput 게이트의 열림상태는 입력 x_t와 이전 상태 h_t-1로부터 구한다\n",
    "\n",
    "$o\\ =\\ \\sigma \\left(x_tW_x^{^{\\left(o\\right)}}+h_{t-1}W_h^{^{\\left(o\\right)}}+b^{^{\\left(o\\right)}}\\right)\\ \\ \\ \\ \\ \\ ,\\ \\sigma \\ :\\ sigmoid\\ function$\n",
    "\n",
    "- 위의 식에서 구한 출력 o와 tanh(c_t)의 원소별 곱을 h_t로 출력\n",
    "- o와 tanh(c_t)의 원소별 곱을 아다마르 곱 Hadamard product 이라고 하며 기호로는 ⊙로 나타낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 forget 게이트\n",
    "- 다음으로 할 일은 기억 셀에서 무엇을 잊을까를 명확하게 지시하는 것이다\n",
    "- forget 게이트 추가하여 게이트의 출력 f를 구하고 이전 기억셀인 c_t-1과 원소별 곱을 구한다\n",
    "\n",
    "$f\\ =\\ \\sigma \\left(x_tW_x^{^{\\left(f\\right)}}+h_{t-1}W_h^{^{\\left(f\\right)}}+b^{^{\\left(f\\right)}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 새로운 기억 셀\n",
    "- forget 게이트를 거치면서 이전 시각의 기억 셀로부터 잊어야 할 기억이 삭제\n",
    "- 새로 기억해야 할 정보를 기억 셀에 추가(tanh 노드 추가)\n",
    "- tanh노드가 계산한 결과가 이전 시각의 기억 셀 c_t-1에 더해져 새로운 정보를 추가하여 새로운 기억 생성\n",
    "\n",
    "$g\\ =\\ \\tanh \\left(x_tW_x^{^{\\left(g\\right)}}+h_{t-1}W_h^{^{\\left(g\\right)}}+b^{^{\\left(g\\right)}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 input 게이트\n",
    "- 새로운 기억 셀 g에 input 게이트를 추가\n",
    "- input 게이트는 g의 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단\n",
    "\n",
    "$i\\ =\\ \\sigma \\left(x_tW_x^{^{\\left(i\\right)}}+h_{t-1}W_h^{^{\\left(i\\right)}}+b^{^{\\left(i\\right)}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 LSTM의 기울기 흐름\n",
    "- LSTM의 구조가 어떤 원리로 기울기 소실을 없애줄까?\n",
    "- LSTM의 역전파에서는 행렬 곱이 아닌 원소별 곱이 이뤄지고, 매 시각 다른 게이트 값을 이용해 원소별 곱을 계산한다.\n",
    "- 이처럼 새로운 게이트 값을 이용하므로 곱셈의 효과가 누적되지 않아 기울기 소실이 일어나지 않는다\n",
    "- 곱하기 노드의 계산은 forget 게이트가 제어. \n",
    "- 잊어야 한다고 판단한 기억 셀의 원소에 대해서는 그 기울기가 작아지고 기억해야 한다고 판단한 원소에 대해서는 그 기울기가 약화되지 않은 채로 과거 방향으로 전해진다\n",
    "- 따라서 기억 셀이 장기 의존 관계를 유지(학습)하리라 기대할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LSTM 구현\n",
    "- 아핀 변환 affine transformation : 행렬 변환과 평행 이동(편향)을 결합한 형태(xW+hW+b)의 식을 말한다\n",
    "- LSTM 수행 계산에서 f, g, i, o 네 수식에 포함된 아핀변환을 보면, 네 수식에서 아핀 변환을 개별적으로 수행하지만, 이를 하나의 식으로 정리해 계산할 수 있다\n",
    "\n",
    "$f=\\sigma \\left(x_tW_x^{^{\\left(f\\right)}}+h_{t-1}W_h^{^{\\left(f\\right)}}+b^{^{\\left(f\\right)}}\\right)\\ \\ \\ \\ ,\\ \\ \\ \\ g=\\tanh \\left(x_tW_x^{^{\\left(g\\right)}}+h_{t-1}W_h^{^{\\left(g\\right)}}+b^{^{\\left(g\\right)}}\\right)$\n",
    "\n",
    "$i=\\sigma \\left(x_tW_x^{^{\\left(i\\right)}}+h_{t-1}W_h^{^{\\left(i\\right)}}+b^{^{\\left(i\\right)}}\\right)\\ \\ \\ \\ \\ \\ \\ \\ ,\\ \\ \\ \\ o=\\sigma \\left(x_tW_x^{^{\\left(o\\right)}}+h_{t-1}W_h^{^{\\left(o\\right)}}+b^{^{\\left(o\\right)}}\\right)$\n",
    "\n",
    "$\\Rightarrow \\ x_t\\ \\left[W_x^{^{\\left(f\\right)}}\\ W_x^{^{\\left(g\\right)}}\\ W_x^{^{\\left(i\\right)}}\\ W_x^{^{\\left(o\\right)}}\\right]\\ +\\ h_{t-1\\ }\\ \\left[W_x^{^{\\left(f\\right)}}\\ W_x^{^{\\left(g\\right)}}\\ W_x^{^{\\left(i\\right)}}\\ W_x^{^{\\left(o\\right)}}\\right]\\ +\\ \\left[b^{^{\\left(f\\right)}}\\ b^{^{\\left(g\\right)}}\\ \\ b^{^{\\left(i\\right)}}\\ b^{^{\\left(o\\right)}}\\right]$\n",
    "\n",
    "$c_t=f\\ \\odot \\ c_{t-1}+g\\ \\odot \\ i\\ \\ \\ \\ ,\\ \\ \\ \\ h_t=o\\ \\odot \\ \\tanh \\left(c_t\\right)$\n",
    "\n",
    "- 4개의 가중치(또는 편향)를 하나로 모을 수 있고, 개별적으로 총 4번 수행하던 아핀 변환을 단 1회의 계산으로 끝낼수 있어 계산속도가 빨라진다\n",
    "- slice 는 아핀 변환의 결과(행렬)를 균등하게 네조각으로 꺼내주는 단순한 노드\n",
    "- slice 노드 다음에는 활성화 함수(sigmoid or tanh)를 거쳐 계산을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향 (4개분의 편향이 담겨 있음）  \n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.matmul(x, Wx) + np.matmul(h_prev, Wh) + b\n",
    "\n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Time LSTM 구현\n",
    "- T개분의 시계열 데이터를 한꺼번에 처리하는 계층\n",
    "- Truncated BPTT는 역전파의 연결은 적당한 길이로 끊고 순전파의 흐름은 그대로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layers = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "            self.dh = dh\n",
    "            return dxs\n",
    "        \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LSTM을 사용한 언어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch06')\n",
    "from common.time_layers import *\n",
    "import pickle\n",
    "\n",
    "class Rnnlm:\n",
    "    def __init__(self, vocab_size=10000, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, r * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, v) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_w, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "\n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "\n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10001.60\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 6[s] | 퍼플렉서티 2597.52\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 13[s] | 퍼플렉서티 1208.02\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 20[s] | 퍼플렉서티 954.23\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 25[s] | 퍼플렉서티 787.24\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 31[s] | 퍼플렉서티 665.38\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 37[s] | 퍼플렉서티 649.84\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 43[s] | 퍼플렉서티 603.59\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 48[s] | 퍼플렉서티 579.12\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 54[s] | 퍼플렉서티 590.51\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 60[s] | 퍼플렉서티 508.63\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 67[s] | 퍼플렉서티 490.85\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 74[s] | 퍼플렉서티 445.84\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 80[s] | 퍼플렉서티 467.78\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 87[s] | 퍼플렉서티 451.76\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 93[s] | 퍼플렉서티 395.04\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 97[s] | 퍼플렉서티 342.84\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 101[s] | 퍼플렉서티 398.12\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 104[s] | 퍼플렉서티 410.71\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 108[s] | 퍼플렉서티 328.43\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 112[s] | 퍼플렉서티 354.25\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 116[s] | 퍼플렉서티 345.16\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 120[s] | 퍼플렉서티 326.21\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 124[s] | 퍼플렉서티 328.33\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 128[s] | 퍼플렉서티 303.24\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 132[s] | 퍼플렉서티 315.26\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 136[s] | 퍼플렉서티 302.17\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 140[s] | 퍼플렉서티 319.95\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 143[s] | 퍼플렉서티 288.51\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 147[s] | 퍼플렉서티 256.04\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 151[s] | 퍼플렉서티 335.42\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 154[s] | 퍼플렉서티 313.52\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 158[s] | 퍼플렉서티 283.40\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 162[s] | 퍼플렉서티 267.30\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 165[s] | 퍼플렉서티 231.04\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 169[s] | 퍼플렉서티 251.15\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 173[s] | 퍼플렉서티 259.73\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 177[s] | 퍼플렉서티 219.71\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 180[s] | 퍼플렉서티 230.34\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 184[s] | 퍼플렉서티 218.49\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 188[s] | 퍼플렉서티 237.08\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 191[s] | 퍼플렉서티 224.37\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 195[s] | 퍼플렉서티 227.23\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 199[s] | 퍼플렉서티 220.26\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 203[s] | 퍼플렉서티 204.78\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 207[s] | 퍼플렉서티 254.56\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 211[s] | 퍼플렉서티 225.99\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 215[s] | 퍼플렉서티 228.06\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 219[s] | 퍼플렉서티 242.77\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 223[s] | 퍼플렉서티 228.11\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 227[s] | 퍼플렉서티 191.75\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 230[s] | 퍼플렉서티 226.13\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 234[s] | 퍼플렉서티 206.98\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 238[s] | 퍼플렉서티 196.85\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 242[s] | 퍼플렉서티 167.83\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 246[s] | 퍼플렉서티 193.57\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 249[s] | 퍼플렉서티 226.85\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 253[s] | 퍼플렉서티 208.14\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 257[s] | 퍼플렉서티 198.52\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 260[s] | 퍼플렉서티 188.57\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 264[s] | 퍼플렉서티 161.15\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 268[s] | 퍼플렉서티 160.22\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 271[s] | 퍼플렉서티 188.06\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 275[s] | 퍼플렉서티 171.17\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 279[s] | 퍼플렉서티 178.62\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 282[s] | 퍼플렉서티 221.10\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 286[s] | 퍼플렉서티 209.25\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 287[s] | 퍼플렉서티 224.00\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 291[s] | 퍼플렉서티 203.08\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 295[s] | 퍼플렉서티 190.96\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 298[s] | 퍼플렉서티 175.08\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 302[s] | 퍼플렉서티 158.54\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 306[s] | 퍼플렉서티 153.04\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 309[s] | 퍼플렉서티 160.44\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 313[s] | 퍼플렉서티 177.51\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 317[s] | 퍼플렉서티 189.78\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 320[s] | 퍼플렉서티 198.74\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 324[s] | 퍼플렉서티 184.12\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 328[s] | 퍼플렉서티 182.54\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 331[s] | 퍼플렉서티 173.93\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 335[s] | 퍼플렉서티 186.50\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 339[s] | 퍼플렉서티 185.50\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 342[s] | 퍼플렉서티 168.04\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 346[s] | 퍼플렉서티 139.82\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 350[s] | 퍼플렉서티 171.49\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 353[s] | 퍼플렉서티 197.89\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 357[s] | 퍼플렉서티 154.05\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 361[s] | 퍼플렉서티 169.31\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 364[s] | 퍼플렉서티 156.59\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 368[s] | 퍼플렉서티 163.43\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 372[s] | 퍼플렉서티 157.29\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 375[s] | 퍼플렉서티 156.38\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 379[s] | 퍼플렉서티 168.31\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 383[s] | 퍼플렉서티 171.66\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 386[s] | 퍼플렉서티 174.44\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 390[s] | 퍼플렉서티 155.37\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 394[s] | 퍼플렉서티 138.54\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 397[s] | 퍼플렉서티 189.20\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 401[s] | 퍼플렉서티 183.03\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 404[s] | 퍼플렉서티 164.83\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 408[s] | 퍼플렉서티 154.01\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 412[s] | 퍼플렉서티 129.18\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 416[s] | 퍼플렉서티 150.15\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 419[s] | 퍼플렉서티 160.07\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 423[s] | 퍼플렉서티 133.43\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 426[s] | 퍼플렉서티 130.97\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 430[s] | 퍼플렉서티 134.81\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 434[s] | 퍼플렉서티 146.44\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 437[s] | 퍼플렉서티 145.69\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 441[s] | 퍼플렉서티 143.40\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 445[s] | 퍼플렉서티 146.36\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 448[s] | 퍼플렉서티 128.97\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 452[s] | 퍼플렉서티 165.17\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 456[s] | 퍼플렉서티 147.15\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 459[s] | 퍼플렉서티 153.47\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 463[s] | 퍼플렉서티 164.33\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 467[s] | 퍼플렉서티 154.27\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 470[s] | 퍼플렉서티 130.88\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 474[s] | 퍼플렉서티 156.09\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 478[s] | 퍼플렉서티 142.84\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 481[s] | 퍼플렉서티 129.45\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 485[s] | 퍼플렉서티 109.65\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 489[s] | 퍼플렉서티 120.18\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 492[s] | 퍼플렉서티 153.61\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 497[s] | 퍼플렉서티 141.44\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 501[s] | 퍼플렉서티 132.86\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 505[s] | 퍼플렉서티 133.37\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 509[s] | 퍼플렉서티 112.06\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 513[s] | 퍼플렉서티 109.29\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 517[s] | 퍼플렉서티 130.32\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 521[s] | 퍼플렉서티 122.60\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 525[s] | 퍼플렉서티 122.32\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 529[s] | 퍼플렉서티 156.00\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 533[s] | 퍼플렉서티 152.50\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 535[s] | 퍼플렉서티 161.56\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 539[s] | 퍼플렉서티 143.72\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 543[s] | 퍼플렉서티 135.39\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 547[s] | 퍼플렉서티 126.57\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 551[s] | 퍼플렉서티 115.33\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 555[s] | 퍼플렉서티 106.15\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 559[s] | 퍼플렉서티 116.08\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 563[s] | 퍼플렉서티 125.51\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 567[s] | 퍼플렉서티 141.99\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 571[s] | 퍼플렉서티 150.21\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 575[s] | 퍼플렉서티 141.05\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 579[s] | 퍼플렉서티 138.96\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 583[s] | 퍼플렉서티 132.69\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 587[s] | 퍼플렉서티 139.25\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 591[s] | 퍼플렉서티 141.87\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 595[s] | 퍼플렉서티 124.14\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 599[s] | 퍼플렉서티 102.24\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 602[s] | 퍼플렉서티 123.83\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 606[s] | 퍼플렉서티 152.71\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 610[s] | 퍼플렉서티 114.29\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 614[s] | 퍼플렉서티 130.83\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 618[s] | 퍼플렉서티 113.50\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 622[s] | 퍼플렉서티 122.98\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 626[s] | 퍼플렉서티 117.75\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 630[s] | 퍼플렉서티 118.81\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 634[s] | 퍼플렉서티 127.14\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 638[s] | 퍼플렉서티 137.17\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 642[s] | 퍼플렉서티 136.78\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 646[s] | 퍼플렉서티 119.27\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 650[s] | 퍼플렉서티 105.13\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 654[s] | 퍼플렉서티 149.20\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 658[s] | 퍼플렉서티 144.46\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 662[s] | 퍼플렉서티 129.70\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 666[s] | 퍼플렉서티 119.92\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 670[s] | 퍼플렉서티 99.50\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 674[s] | 퍼플렉서티 117.72\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 678[s] | 퍼플렉서티 126.51\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 682[s] | 퍼플렉서티 107.25\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 685[s] | 퍼플렉서티 102.60\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 689[s] | 퍼플렉서티 104.03\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 693[s] | 퍼플렉서티 114.67\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 697[s] | 퍼플렉서티 117.81\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 701[s] | 퍼플렉서티 114.04\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 705[s] | 퍼플렉서티 120.08\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 709[s] | 퍼플렉서티 105.66\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 712[s] | 퍼플렉서티 130.56\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 716[s] | 퍼플렉서티 118.50\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 720[s] | 퍼플렉서티 127.37\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 724[s] | 퍼플렉서티 132.23\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 728[s] | 퍼플렉서티 123.27\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 732[s] | 퍼플렉서티 108.53\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 735[s] | 퍼플렉서티 128.04\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 739[s] | 퍼플렉서티 119.29\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 743[s] | 퍼플렉서티 103.27\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 747[s] | 퍼플렉서티 88.48\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 751[s] | 퍼플렉서티 95.51\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 755[s] | 퍼플렉서티 121.28\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 759[s] | 퍼플렉서티 114.95\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 763[s] | 퍼플렉서티 106.54\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 766[s] | 퍼플렉서티 111.03\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 770[s] | 퍼플렉서티 94.04\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 774[s] | 퍼플렉서티 88.59\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 778[s] | 퍼플렉서티 105.78\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 782[s] | 퍼플렉서티 104.59\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 786[s] | 퍼플렉서티 101.41\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 789[s] | 퍼플렉서티 129.14\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 793[s] | 퍼플렉서티 126.32\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 795[s] | 퍼플렉서티 135.96\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 799[s] | 퍼플렉서티 122.28\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 802[s] | 퍼플렉서티 107.77\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 806[s] | 퍼플렉서티 106.79\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 810[s] | 퍼플렉서티 94.54\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 814[s] | 퍼플렉서티 86.77\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 818[s] | 퍼플렉서티 96.12\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 822[s] | 퍼플렉서티 102.75\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 826[s] | 퍼플렉서티 118.10\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 829[s] | 퍼플렉서티 129.28\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 833[s] | 퍼플렉서티 120.08\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 837[s] | 퍼플렉서티 120.36\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 841[s] | 퍼플렉서티 113.89\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 845[s] | 퍼플렉서티 115.00\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 848[s] | 퍼플렉서티 121.45\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 852[s] | 퍼플렉서티 104.46\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 856[s] | 퍼플렉서티 84.96\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 859[s] | 퍼플렉서티 100.23\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 863[s] | 퍼플렉서티 128.49\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 867[s] | 퍼플렉서티 96.81\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 870[s] | 퍼플렉서티 111.75\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 874[s] | 퍼플렉서티 94.32\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 878[s] | 퍼플렉서티 103.01\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 882[s] | 퍼플렉서티 100.15\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 885[s] | 퍼플렉서티 102.13\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 889[s] | 퍼플렉서티 107.20\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 893[s] | 퍼플렉서티 117.37\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 896[s] | 퍼플렉서티 114.15\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 900[s] | 퍼플렉서티 103.90\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 904[s] | 퍼플렉서티 89.29\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 907[s] | 퍼플렉서티 127.53\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 911[s] | 퍼플렉서티 122.90\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 914[s] | 퍼플렉서티 112.17\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 918[s] | 퍼플렉서티 103.07\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 922[s] | 퍼플렉서티 84.88\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 925[s] | 퍼플렉서티 101.49\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 929[s] | 퍼플렉서티 108.16\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 933[s] | 퍼플렉서티 95.54\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 936[s] | 퍼플렉서티 87.85\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 940[s] | 퍼플렉서티 88.25\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 944[s] | 퍼플렉서티 98.45\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 947[s] | 퍼플렉서티 102.87\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 951[s] | 퍼플렉서티 97.34\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 955[s] | 퍼플렉서티 105.03\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 958[s] | 퍼플렉서티 90.80\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 962[s] | 퍼플렉서티 114.98\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 966[s] | 퍼플렉서티 102.84\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 969[s] | 퍼플렉서티 112.86\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 973[s] | 퍼플렉서티 113.32\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 976[s] | 퍼플렉서티 106.47\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 980[s] | 퍼플렉서티 97.85\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 984[s] | 퍼플렉서티 113.83\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 987[s] | 퍼플렉서티 104.33\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 991[s] | 퍼플렉서티 90.47\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 995[s] | 퍼플렉서티 79.14\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 998[s] | 퍼플렉서티 80.00\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1002[s] | 퍼플렉서티 104.31\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1006[s] | 퍼플렉서티 100.83\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1009[s] | 퍼플렉서티 92.28\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1013[s] | 퍼플렉서티 96.20\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1017[s] | 퍼플렉서티 83.71\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1020[s] | 퍼플렉서티 76.38\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1024[s] | 퍼플렉서티 91.89\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1027[s] | 퍼플렉서티 92.89\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1031[s] | 퍼플렉서티 88.80\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1035[s] | 퍼플렉서티 110.89\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1038[s] | 퍼플렉서티 110.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "c:\\Users\\GIGABYTE\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  135.52704822629613\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# PTB 데이터셋 학습\n",
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch06')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import  RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RNNLM 추가개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 LSTM 계층 다양화\n",
    "- RNNLM으로 정확한 모델을 만들고자 한다면 많은 경우 LSTM 계층을 깊게 쌓아 효과를 볼 수 있다\n",
    "- 층이 여려겹 쌓일 수록 언어 모델의 정확도가 향상되고 더 복잡한 패턴을 학습할 수 있게 된다\n",
    "- 몇 층을 쌓아야 할까? 하이퍼파라미터는 처리할 데이터의 복잡도나 학습 데이터 양에 따라 적절히 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 드롭아웃에 의한 과적합 억제\n",
    "- 층을 깊게 쌓음으로써 표현력이 풍부한 모델을 만들 수 있으나 종종 과적합을 일으킨다\n",
    "- RNN은 일반적인 피드포워드 신경망보다 쉽게 과적합을 일으켜 대책이 중요하고 현재도 활발하게 연구되는 주제\n",
    "- 과적합을 억제하는 전통적인 방법은 훈련 데이터의 양 늘리기와 모델의 복잡도 줄이기, 복잡도에 페널티를 주는 정규화, 드롭아웃처럼 훈련 시 계층 내의 뉴런 몇 개를 무작위로 무시하고 학습하는 방법 등\n",
    "- 드롭아웃 dropout은 무작위로 뉴런을 선택하여 선택한 뉴런을 무시(신호 전달을 막는다). 무작위 무시가 제약이 되어 신경망의 일반화 성능을 개선\n",
    "- RNN에서 시계열 방향으로 드롭아웃을 넣으버리면 흐르는 시간에 비례해 드롭아웃에 의한 노이즈가 축적되어 정보가 사라질 수 있다\n",
    "- 일반적인 드롭아웃은 깊이 방향으로 삽입하여 시간 방향으로 아무리 진행해도 정보를 잃지 않는다\n",
    "- 변형 드롭아웃은 깊이 방향은 물론 시간 방향에도 이용할 수 있어서 정확도를 향상\n",
    "- 같은 계층의 드롭아웃끼리 마스크를 공유함으로써 마스크가 고정되며 정보를 잃게 되는 방법도 고정되므로 정보의 지수적 손실을 예방"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 가중치 공유 weight tying\n",
    "- 계층이 가중치를 공유함으로써 학습하는 매개변수 수가 크게 줄어드는 동시에 정확도도 향상되는 기술\n",
    "- Embedding 계층과 Affine 계층이 가중치를 연결(공유) 할경우 가중치 구현 관점에서 살펴보면\n",
    "- 어휘수를 V LSTM의 은닉 차원이 H라 할때 Embedding 계층의 가중치는 형상이 V x H 이며\n",
    "- Affine 계층의 가중치 형상은 H x V가 된다. Embedding 계층의 가중치를 전치하여 Affine 계층의 가중치로 설정하기만 하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 개선된 RNNLM 구현\n",
    "- LSTM 계층의 다층화\n",
    "- 드롭아웃 사용(깊이방향)\n",
    "- 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch06')\n",
    "from common.time_layers import *\n",
    "from common.np import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordbec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(D, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 세가지 개선\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b) # 가중치 공유\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch06')\n",
    "from common import config\n",
    "# GPU 실행시 아래 주석 해제(쿠파이 필요)\n",
    "# ====================================\n",
    "# config.GPU = True\n",
    "# ====================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티 : ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:/Python/14.밑바닥부터시작하는딥러닝/2/ch06')\n",
    "from common import config\n",
    "# GPU 실행시 아래 주석 해제(쿠파이 필요)\n",
    "# ====================================\n",
    "config.GPU = True\n",
    "# ====================================\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from better_rnnlm import BetterRnnlm\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티 : ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 정리\n",
    "- 단순한 RNN의 학습에서는 기울기 소실과 기울기 폭발이 문제가 된다\n",
    "- 기울기 폭발에는 기울기 클리핑, 기울기 소실에는 게이트가 추가된 RNN(LSTM과 GRU 등)이 효과적이다\n",
    "- LSTM에는 input 게이트, forget 게이트, output 게이트 3개의 게이트가 있다\n",
    "- 게이트에는 전용 가중치가 있으며, 시그모이드 함수를 사용하여 0.0~1.0 사이의 실수를 출력한다\n",
    "- 언어 모델 개선에는 LSTM 계층 다층화, 드롭아웃, 가중치 공유 등의 기법이 효과적이다\n",
    "- RNN의 정규화는 중요한 주제이며, 드롭아웃 기반의 다양한 기법이 제안되고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46e7d24ecb1dc1117e8330ee9e498b85da846e4ffb1348d12e4a7f0695b68a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
